# machine-learning-evaluation-and-deployment
This lab focuses on the evaluation and deployment stages of the machine learning life cycle, using logistic regression to solve a binary classification problem based on Airbnb listings data. You begin by loading a fully preprocessed dataset and defining the ML problem: predicting whether a host is a “superhost.” The label is extracted from the host_is_superhost column, while all remaining columns serve as features. After creating labeled examples, the dataset is split into training and test sets to prepare for model evaluation. This setup ensures that the model’s performance can be measured on unseen data, a critical component of the evaluation phase.

The next phase of the lab involves training, testing, and evaluating logistic regression models using scikit-learn. You first train a default logistic regression model and assess its performance through predicted probabilities, predicted class labels, and a confusion matrix. The lab then introduces model selection through hyperparameter tuning using GridSearchCV, specifically searching over different values of the regularization parameter C. After identifying the optimal value of C, you retrain the model and compare its test-set performance to the default model. You also generate precision-recall curves, ROC curves, and AUC scores for both models, allowing you to analyze trade-offs between precision, recall, true-positive rate, and false-positive rate. The lab additionally includes a feature-selection component using SelectKBest, demonstrating how model performance can be influenced by the number and relevance of features.

The final portion of the lab focuses on deployment, guiding you through saving your trained model for future use. You serialize the optimal logistic regression model using Python’s pickle module, save it to a .pkl file, and reload it to verify that it can still make predictions. This step demonstrates how ML models are packaged and persisted in real-world workflows, enabling deployment in applications, reuse by teams, and integration into larger systems. The lab concludes by having you download the trained model and dataset for upload to a GitHub repository, reinforcing best practices for versioning and sharing machine learning artifacts.
